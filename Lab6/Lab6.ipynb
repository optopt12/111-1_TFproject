{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow進階技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers\n",
    "透過繼承`tf.keras.layers.Layer`類別，來輕鬆創建字定義的網路層。\n",
    "\n",
    "你可以到https://www.tensorflow.org/api_docs/python/tf/keras/layers 官方API察看更多的網路層。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: 簡單的客自化Convolutional layers。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=(1, 1), padding=\"VALID\", **kwargs):\n",
    "        super(CustomConv2D, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = (1, *strides, 1)\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        kernel_h, kernel_w = self.kernel_size\n",
    "        input_dim = input_shape[-1]\n",
    "        # 創建卷積的權重值(weights)\n",
    "        self.w = self.add_weight(name='kernel', \n",
    "                                 shape=(kernel_h, kernel_w, input_dim, self.filters),\n",
    "                                 initializer='glorot_uniform',  # 設定初始化方法\n",
    "                                 trainable=True)  # 設定這個權重是否能夠訓練(更動)\n",
    "        # 創建卷積的偏差值(bias)\n",
    "        self.b = self.add_weight(name='bias', \n",
    "                                 shape=(self.filters,),\n",
    "                                 initializer='zeros',  # 設定初始化方法\n",
    "                                 trainable=True)  # 設定這個權重是否能夠訓練(更動)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, self.w, self.strides, padding=self.padding) # 卷積運算\n",
    "        x = tf.nn.bias_add(x, self.b)  # 加上偏差值\n",
    "        x = tf.nn.relu(x)  # 激活函數\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss\n",
    "\n",
    "在設計進階的研究方法或更深入解決問題時，TensorFlow官方文件所提供的損失函數，通常不夠使用，這時候你就必須自己定義損失函數，實作自己設計的損失函數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: 簡單的客自化Crossentropy Loss。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_categorical_crossentropy(y_true, y_pred):\n",
    "    # x = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_pred), reduction_indices=[1]))\n",
    "    x = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "\n",
    "如果你需要的指標函數官方API並沒有提供，你可以通過繼承`tf.keras.metrics.Metric`類別，來輕鬆創建自定義的指標函數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: 計算多少個樣本是正確分類的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCategoricalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='custom_catrgorical_accuracy', **kwargs):\n",
    "        super(CustomCategoricalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        # 記錄正確預測的數量\n",
    "        self.correct = self.add_weight('correct_numbers', initializer='zeros')\n",
    "        # 記錄全部資料的量數\n",
    "        self.total = self.add_weight('total_numbers', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # 輸入答案為One-hot編碼，所以取最大的數值為答案\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        # 取預測輸出最大的數值為預測結果\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        # 比較預測結果是否正確，正確會返回True(正確)，錯誤會返回False(錯誤)\n",
    "        values = tf.equal(y_true, y_pred)\n",
    "        # 轉為浮點數True(正確)=1.0，False(錯誤)=0.0\n",
    "        values = tf.cast(values, tf.float32)\n",
    "        # 將values所有數值相加就會等於正確預測的總數\n",
    "        values_sum = tf.reduce_sum(values)\n",
    "        # 計算這個Batch的資料數量\n",
    "        num_values = tf.cast(tf.size(values), tf.float32)\n",
    "        self.correct.assign_add(values_sum)  # 更新正確預測的總數\n",
    "        self.total.assign_add(num_values)  # 更新資料量的總數\n",
    "\n",
    "    def result(self):\n",
    "        # 計算準確率\n",
    "        return tf.math.divide_no_nan(self.correct, self.total)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # 每一次Epoch結束後會重新初始化變數\n",
    "        self.correct.assign(0.)\n",
    "        self.total.assign(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Callbacks\n",
    "\n",
    "如果你需要的監控或執行的操作官方的Callbacks函數沒有提供，你可以通過繼承`tf.keras.callbacks.Callback`類別，來輕鬆創建字定義的Callbacks函數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: 紀錄每一個batch的loss值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, weights_file, monitor='loss', mode='min', save_weights_only=False):\n",
    "        super(SaveModel, self).__init__()\n",
    "        self.weights_file = weights_file\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_weights_only = save_weights_only\n",
    "        if mode == 'min':\n",
    "            self.best = np.Inf\n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "        \n",
    "    def save_model(self):\n",
    "        if self.save_weights_only:\n",
    "            self.model.save_weights(self.weights_file)\n",
    "        else:\n",
    "            self.model.save(self.weights_file)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        if self.mode == 'min' and monitor_value < self.best:\n",
    "            self.save_model()\n",
    "            self.best = monitor_value\n",
    "        elif self.mode == 'max' and monitor_value > self.best:\n",
    "            self.save_model()\n",
    "            self.best = monitor_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗：比較Keras高階API和客製化API兩種網路訓練的結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 必要套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "# from preprocessing import parse_aug_fn, parse_fn\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import image_preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def flip(x):\n",
    "    \"\"\"\n",
    "    flip image(翻轉影像)\n",
    "    \"\"\"\n",
    "    x = tf.image.random_flip_left_right(x)  # 隨機左右翻轉影像\n",
    "    return x\n",
    "\n",
    "def color(x):\n",
    "    \"\"\"\n",
    "     Color change(改變顏色)\n",
    "    \"\"\"\n",
    "    x = tf.image.random_hue(x, 0.08)  # 隨機調整影像色調\n",
    "    x = tf.image.random_saturation(x, 0.6, 1.6)  # 隨機調整影像飽和度\n",
    "    x = tf.image.random_brightness(x, 0.05)  # 隨機調整影像亮度\n",
    "    x = tf.image.random_contrast(x, 0.7, 1.3)  # 隨機調整影像對比度\n",
    "    return x\n",
    "\n",
    "def rotate(x):\n",
    "    \"\"\"\n",
    "    Rotation image(影像旋轉)\n",
    "    \"\"\"\n",
    "    # 隨機選轉n次(通過minval和maxval設定n的範圍)，每次選轉90度\n",
    "    x = tf.image.rot90(x, tf.random.uniform(shape=[], minval=1, maxval=4, dtype=tf.int32))\n",
    "    return x\n",
    "\n",
    "def zoom(x, scale_min=0.6, scale_max=1.4):\n",
    "    \"\"\"\n",
    "    Zoom Image(影像縮放)\n",
    "    \"\"\"\n",
    "    h, w, c = x.shape\n",
    "    scale = tf.random.uniform([], scale_min, scale_max)  # 隨機縮放比例\n",
    "    sh = h * scale  # 縮放後影像長度\n",
    "    sw = w * scale  # 縮放後影像寬度\n",
    "    x = tf.image.resize(x, (sh, sw))  # 影像縮放\n",
    "    x = tf.image.resize_with_crop_or_pad(x, h, w)  # 影像裁減和填補\n",
    "    return x\n",
    "\n",
    "def parse_aug_fn(dataset):\n",
    "    \"\"\"\n",
    "    Image Augmentation(影像增強) function\n",
    "    \"\"\"\n",
    "    x = tf.cast(dataset['image'], tf.float32) / 255.  # 影像標準化\n",
    "    x = flip(x)  # 隨機水平翻轉\n",
    "    # 觸發顏色轉換機率50%\n",
    "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.5, lambda: color(x), lambda: x)\n",
    "    # 觸發影像旋轉機率0.25%\n",
    "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.75, lambda: rotate(x), lambda: x)\n",
    "    # 觸發影像縮放機率50%\n",
    "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.5, lambda: zoom(x), lambda: x)\n",
    "    # 將輸出標籤轉乘One-hot編碼\n",
    "    y = tf.one_hot(dataset['label'], 10)\n",
    "    return x, y\n",
    "\n",
    "def parse_fn(dataset):\n",
    "    x = tf.cast(dataset['image'], tf.float32) / 255.  # 影像標準化\n",
    "    # 將輸出標籤轉乘One-hot編碼\n",
    "    y = tf.one_hot(dataset['label'], 10)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar 10\n",
    "載入Cifar10數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將train Data重新分成1:9等分，分別分給valid data, train data\n",
    "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
    "# 取得訓練數據，並順便讀取data的資訊\n",
    "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
    "# 取得驗證數據\n",
    "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
    "# 取得測試數據\n",
    "test_data = tfds.load(\"cifar10\", split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
    "batch_size = 64  # 批次大小\n",
    "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
    "\n",
    "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
    "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
    "train_data = train_data.map(map_func=image_preprocessing.parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "valid_data = valid_data.map(map_func=image_preprocessing.parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
    "test_data = test_data.map(map_func=image_preprocessing.parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
    "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 使用Keras高階API訓練網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 128)         295040    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 64)          73792     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                200768    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 941,066\n",
      "Trainable params: 941,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
    "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存訓練記錄檔\n",
    "logs_dirs = 'lab6-logs'\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir='lab6-logs')\n",
    "\n",
    "# 紀錄每一個batch的Loss值變化\n",
    "model_dirs = logs_dirs + '/models'\n",
    "os.makedirs(model_dirs, exist_ok=True)\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(model_dirs + '/save.h5', \n",
    "                                                monitor='val_catrgorical_accuracy', \n",
    "                                                mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定訓練使用的優化器、客自化損失函數和客自化指標函數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定訓練使用的優化器、損失函數和指標函數\n",
    "model_1.compile(keras.optimizers.Adam(), \n",
    "                loss=keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "                metrics=[keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CodeData\\111-1_tfproject\\lab6\\Lab6.ipynb Cell 29\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 訓練網路模型\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_1\u001b[39m.\u001b[39;49mfit(train_data,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             validation_data\u001b[39m=\u001b[39;49mvalid_data,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[model_cbk, save_model])\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 訓練網路模型\n",
    "model_1.fit(train_data,\n",
    "            epochs=100, \n",
    "            validation_data=valid_data,\n",
    "            callbacks=[model_cbk, save_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用客自化API訓練網路模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Custom Layer：將原本的Conv2d改成CustomConv2D。\n",
    "- Custom Loss：將原本的CategoricalCrossentropy改成custom_loss。\n",
    "- Custom Metrics：加入一個新的指標函數CatgoricalTruePositives。\n",
    "- Custom Callbacks：紀錄每一個batch的Loss值變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model-2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " custom_conv2d (CustomConv2D  (None, 30, 30, 64)       1792      \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " custom_conv2d_1 (CustomConv  (None, 13, 13, 128)      73856     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " custom_conv2d_2 (CustomConv  (None, 11, 11, 256)      295168    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " custom_conv2d_3 (CustomConv  (None, 9, 9, 128)        295040    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " custom_conv2d_4 (CustomConv  (None, 7, 7, 64)         73792     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                200768    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 941,066\n",
      "Trainable params: 941,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = CustomConv2D(64, (3, 3))(inputs)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = CustomConv2D(128, (3, 3))(x)\n",
    "x = CustomConv2D(256, (3, 3))(x)\n",
    "x = CustomConv2D(128, (3, 3))(x)\n",
    "x = CustomConv2D(64, (3, 3))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
    "model_2 = keras.Model(inputs, outputs, name='model-2')\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存訓練記錄檔\n",
    "logs_dirs = 'lab6-logs'\n",
    "model_cbk = keras.callbacks.TensorBoard(log_dir='lab6-logs')\n",
    "\n",
    "# 紀錄每一個batch的Loss值變化\n",
    "model_dirs = logs_dirs + '/models'\n",
    "os.makedirs(model_dirs, exist_ok=True)\n",
    "custom_save_model = SaveModel(model_dirs + '/custom_save.h5', \n",
    "                              monitor='val_custom_catrgorical_accuracy', \n",
    "                              mode='max', \n",
    "                              save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer CustomConv2D has arguments ['self', 'filters', 'kernel_size', 'strides', 'padding']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer CustomConv2D has arguments ['self', 'filters', 'kernel_size', 'strides', 'padding']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 23/704 [..............................] - ETA: 2:29 - loss: 2.3055 - custom_catrgorical_accuracy: 0.1012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CodeData\\111-1_tfproject\\lab6\\Lab6.ipynb Cell 34\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_2\u001b[39m.\u001b[39mcompile(keras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m            loss\u001b[39m=\u001b[39mcustom_categorical_crossentropy, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m            metrics\u001b[39m=\u001b[39m[CustomCategoricalAccuracy()])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 訓練網路模型\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_2\u001b[39m.\u001b[39;49mfit(train_data,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             validation_data\u001b[39m=\u001b[39;49mvalid_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CodeData/111-1_tfproject/lab6/Lab6.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49m[model_cbk, custom_save_model])\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 設定訓練使用的優化器、損失函數和指標函數\n",
    "model_2.compile(keras.optimizers.Adam(), \n",
    "           loss=custom_categorical_crossentropy, \n",
    "           metrics=[CustomCategoricalAccuracy()])\n",
    "\n",
    "# 訓練網路模型\n",
    "model_2.fit(train_data,\n",
    "            epochs=100, \n",
    "            validation_data=valid_data,\n",
    "            callbacks=[model_cbk, custom_save_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比較兩種方法的訓練結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入兩種方法的模型權重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.load_weights(model_dirs+'/save.h5')\n",
    "model_2.load_weights(model_dirs+'/custom_save.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驗證網路模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 9s 54ms/step - loss: 0.6681 - categorical_accuracy: 0.7856\n",
      "  1/157 [..............................] - ETA: 29s - loss: 0.8047 - custom_catrgorical_accuracy: 0.7969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ren-jing\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2086: UserWarning: Metric CustomCategoricalAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 8s 52ms/step - loss: 0.6466 - custom_catrgorical_accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668097</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.646603</td>\n",
       "      <td>0.7910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss  Accuracy\n",
       "0  0.668097    0.7856\n",
       "1  0.646603    0.7910"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_1, acc_1 = model_1.evaluate(test_data)\n",
    "loss_2, acc_2 = model_2.evaluate(test_data)\n",
    "loss = [loss_1, loss_2]  \n",
    "acc = [acc_1, acc_2]\n",
    "dict = {\"Loss\": loss, \"Accuracy\": acc}\n",
    "pd.DataFrame(dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "59e28edaca8d48efe3ba8b1a9cfaf5b90f86910db2db3c89dd8dac6b042bae31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
